# ðŸ“¦ MongoDB CSV to SQL Server Importer

This Python script automates the import of multiple `.csv` files (exported from MongoDB) into a SQL Server database. It ensures safe, idempotent data loading by tracking which files have already been imported.

---

## ðŸŽ¯ Purpose

- âœ… Transform MongoDB collection CSV exports into SQL Server tables.
- âœ… Automatically create SQL tables based on CSV headers.
- âœ… Skip already-imported files using a control table.
- âœ… Log all actions and errors to `log.txt`.

---

## ðŸ› ï¸ Features

- ðŸ“ Bulk CSV import from a specified folder
- ðŸ§  Intelligent table and column name sanitization
- ðŸ”„ Idempotent imports (prevents re-importing)
- ðŸ—ƒï¸ Auto SQL table creation with `NVARCHAR(MAX)` columns
- ðŸ§¾ Logging with timestamps in `log.txt`

---

## ðŸ“‚ Project Structure

```
mongo_to_sql_migration/
â”œâ”€â”€ main.py              # Main import logic
â”œâ”€â”€ .env                 # Database config
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ log.txt              # Import logs
â””â”€â”€ MongoDB_Exports/     # Folder containing .csv exports
```

---

## ðŸ”§ .env Configuration

Create a `.env` file in the root folder with the following:

```env
DB_DRIVER={ODBC Driver 17 for SQL Server}
DB_SERVER=localhost\SQLEXPRESS
DB_NAME=YourDatabaseName
DB_USER=your_username
DB_PASSWORD=your_password
EXPORTS_FOLDER=C:\Users\sai hemanth\Desktop\dev\MongoDB_Exports
```

---

## ðŸš€ Usage

1. **Install dependencies**  
   ```bash
   pip install -r requirements.txt
   ```

2. **Run the script**  
   ```bash
   python main.py
   ```

3. **Check logs**  
   Open `log.txt` to view import status or errors.

---

## ðŸ“¦ Requirements

- Python 3.7+
- SQL Server (local or remote)
- ODBC Driver 17 for SQL Server
- Python packages:
  - `pandas`
  - `pyodbc`
  - `python-dotenv`

Install with:

```bash
pip install -r requirements.txt
```

---

## âœ… Safety & Idempotency

- A table `ImportedFiles` keeps track of which CSVs were successfully imported.
- You can safely rerun the script â€” it will **skip** files already processed.

---

## ðŸ§¼ Notes

- Table and column names are sanitized to remove unsupported characters.
- All values are inserted as `NVARCHAR(MAX)` to avoid type mismatch issues.
- Empty or malformed files are automatically skipped and logged.

---

## ðŸ“œ License

MIT License â€“ use freely with attribution.

---

> ðŸ’¬ _Need improvements like datetime casting, array support, or schema inference? PRs welcome or feel free to fork and extend!_
